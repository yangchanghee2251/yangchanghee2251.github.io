---
layout: single
title: "SGT Demo & Evaluation 하는 법"
author_profile: true
categories:
  - tracking

toc_label: "목차"
toc: true
toc_sticky: true
sidebar:
    nav: "sidebar-category"
---

## SGT?
WACV 2023에 accept된 paper다. 이 논문의 정확도가 MOT16에서 mAP 76.8로 3위, HiEve 2위, MOT17 9등, MOT20 8등를 보이고 있다. demo 및 evaluation을 해보기 위한 Post이고 진행해보고자 한다.

## 실험 환경
OS는 Linux 20.04 LTS에 GPU는 RTX 3090 2대이다. cuda버젼은 11.1~11.6 까지 전부 깔아놨지만 지금은 cuda 11.3으로 실험해보고자 한다. github를 확인해본 결과 환경을 Docker로 사용하도록 되어있어 Docker를 사용해서 진행해보고자 한다.

## Docker 사용
[여기](https://github.com/HYUNJS/SGT/blob/main/INSTALL.md)를 보면 환경을 확인할 수 있는데 cuda 11.3에서 평가를 했다고 한다. **Start with Dcoker Image**를 보면 먼저 docker images를 받아야 한다.  
docker는 당연히 깔려있다고 가정을 하고 진행하는데 나는 cuda 11.3을 진행할 거기 때문에 아래 코드를 통해 image를 받아주기로 하자.
```
docker pull jshyunaa/sgt:cu113
```
완료된 코드!
```
Digest: sha256:bc21258bc8476b826f3bf9fa50168a82010aca4547f0484c15cbf8249aed5c1c
Status: Downloaded newer image for jshyunaa/sgt:cu113
docker.io/jshyunaa/sgt:cu113
```
다음으로 docker container를 만들어야 하는데 적어야하는 code를 보면
```
[Template]
docker run --rm -it -d --shm-size=<mem> --gpus '"device=<device-indices>"'  -v <host_root_dir>:<container_root_dir>\
              --name <container_name> -p <ssh_port>:22 -p <log_port>:8081 jshyunaa/sgt:<version>
[Example]
docker run --rm -it -d --shm-size=16G --gpus '"device=0,1"' -v /media/ssd1/users/jshyun/:/root --name sgt -p 3000:22 -p 3001:8081 jshyunaa/sgt:cu113
```
와 같은데 나는 shm-size는 16G로 하고 gpu는 0,1로 사용할 거고 `/media/ssd1/users/jshyun/`만 내 dataset path로 바꾸면 될 것 같다.
```
docker run --rm -it -d --shm-size=16G --gpus '"device=0,1"' -v /home/qazw5741/MOT/SGT:/root --name sgt -p 3000:22 -p 3001:8081 jshyunaa/sgt:cu113
```
docker를 키기 위해서는 아래 코드를 작성
```
docker exec -it sgt /bin/bash
```
위 코드를 치면 docker image로 들어가는데 바로 테스트가 가능하면 좋겟지만... 에러가 조금 나와서 나와 같은 에러가 생겼을 사람에게 공유하고자 좀 더 포스팅 한다.

## Error
1. `/root/projects/SGT/configs/MOT16/sgt_dla34.yaml`을 파일 수정함
WEIGHTS에 들여쓰기가 제대로 되어 있지 않아서 Error가 생겼었고 weight file은 [여기](https://hkustconnect-my.sharepoint.com/personal/jhyunaa_connect_ust_hk/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fjhyunaa%5Fconnect%5Fust%5Fhk%2FDocuments%2FSparseGraphTracker%2FSGT%5Fweights&ga=110)에 있는데 `sgt_dla34_mot17-CH.pth`를 받았음
```
_BASE_: "../Base-SGT.yaml"
MODEL:
  WEIGHTS: "/root/sgt_dla34_mot17-CH.pth"
  TRACKER:
    INIT_DET_THRESH: 0.5
    GNN:
```
2. 기본적으로 Dataset이 SGT안에 포함되어 있어야 됨.  
ex) `SGT/dataset/MOT16` 이런식으로 되어있어야함

3. 실행한 코드  
나같은 경우에는 MOT16을 해보고 싶어서 아래 코드로 변경함.
```
python projects/SGT/train_net.py --config-file projects/SGT/configs/MOT16/sgt_dla34.yaml --data-dir /root/Tracking/ --num-gpu 1 --eval-only OUTPUT_DIR /root/sgt_output/mot16_test/dla34_mot16-CH
```

4. 결과
```
[03/25 15:55:14 projects.Datasets.MOT.evaluation.mot_evaluation]: [MOT16-13] #Detections - 10644
[03/25 15:55:14 projects.Datasets.MOT.evaluation.mot_evaluation]: [MOT16-13] # Recovered Dets - 639
[03/25 15:55:14 projects.SGT.sgt.trainer]: Evaluation results for mot16_test in csv format:
```
위 결과처럼 결과가 나오게 됨.

## Evaluation
Update 23-03-27.  
MOT16의 경우 challenge 형태로 test가 가능하다. 따라서 webpage로 들어간 후에 결과를 확인해야 한다.
좀더 자세한 정보를 알고 싶으면 [MOT16 evaluation](https://yangchanghee2251.github.io/tracking/MOT16_eval/)를 확인하면 된다.
여기서 결과로 나온 .txt file을 알집으로 만들어서 위 링크에 가져가 결과를 확인하면 된다.

<img src="../post_images/result.png" width="1000px"  title="table1" alt=""/>  

## Evaluation MOT16 training set
Update 23-03-27.  
MOT16의 testset은 challenge로부터 결과를 얻지만 training dataset을 얻고 싶은 경우에는 좀 다르게 진행해야 한다.
1. `git clone https://github.com/shenh10/mot_evaluation`를 진행한다.
mot_evaluation을 직접 구현한 코드이며 간단하게 사용 가능하다. 필수적으로 설치할 라이브러리가 존재하는데
```
pip install numpy
pip install scipy
pip install easydict
```
이렇게 3개를 설치해야한다.
2. `python evaluate_tracking.py --seqmap {seqmap_path} --track {res_path} --gt {gt_path}`를 진행한다.
SGT 결과를 돌리기 위해 아래 코드를 진행하면 된다..
```
python evaluate_tracking.py --seqmap seqmaps/test.txt --track ../sgt_MOT16/mot16_test/dla34_mot16-CH/inference/det/ --gt ../Tracking/MOT16/train/
```
만약 seq를 바꾸고 싶다면 `seqmaps/test.txt`를 수정하면 된다.

## Visualization
시각화 하는 방법은 나와 있음 아래 코드를 실행하면 됨.
```
python projects/Datasets/MOT/vis/vis_gt.py --data-root /root/Tracking/ --register-data-name mot16-train
```

`/root/Tracking/MOT16/gt_vis/train/MOT16-02/`에 visualization이 된 결과가 output으로 나옴 여기서 난 gif file로 만들고 싶어서 ffmpeg를 이용해서 애니메이션으로 만들어봤다. (위 디렉토리에서 돌려야됨)

```
ffmpeg -f image2 -framerate 30 -i %06d.jpg -loop -1 02.gif
```
> `%06d.jpg`를 적는 이유는 숫자 6개이기 때문에 6으로 설정하고 loop에 -1을 넣었는데 -1은 loop 한번만 돌리겠다는 의미이다. 0을 넣으면 무한 반복이 되고 다른 숫자를 넣으면 넣은 숫자만큼 반복한다. 마지막 gif는 파일 결과 이름이다.

## Visualization MOT16
Update 23-03-27.  
SGT의 경우 MOT16에 대한 visualization이 없는데 아래 코드를 수정해주면 볼 수 있다.  
`root/projects/Datasets/MOT/vis/commons.py`
line 70번줄 추가
```
SEQ_NAMES_MOT16 = {
    'train': ['MOT16-02', 'MOT16-04', 'MOT16-05', 'MOT16-09', 'MOT16-10', 'MOT16-11', 'MOT16-13'],
    'test': ['MOT16-01', 'MOT16-03', 'MOT16-06', 'MOT16-07', 'MOT16-08', 'MOT16-12', 'MOT16-14'],
}
```

line 95번줄 SEQ_NAMES_DICT 수정
```
SEQ_NAMES_DICT = {
    'mot15': SEQ_NAMES_MOT15,
    'mot16': SEQ_NAMES_MOT16,
    'mot17': SEQ_NAMES_MOT17,
    'mot20': SEQ_NAMES_MOT20,
    'hieve': SEQ_NAMES_HIEVE,
}
```
visualization 확인하는 코드는 다음과 같음
```
python projects/Datasets/MOT/vis/vis_seq_from_txt_result.py --data-root Tracking/ --result-dir /root/sgt_MOT16/mot16_test/dla34_mot16-CH --data-name mot16 --tgt-split train
```


## 후기
2시간 정도 걸렸고 Tracking method는 처음해보는데 생각보다 human pose와 달른 task여서 신기했고 재밌었다. :)